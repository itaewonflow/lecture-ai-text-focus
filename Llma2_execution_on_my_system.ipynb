{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQNpLAtFgzM0znztNuverN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itaewonflow/lecture-ai-text-focus/blob/main/Llma2_execution_on_my_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**How to use LLama 2 on my computer**\n",
        "\n",
        "- Meta's Llama2 7B chat model used n this tutorial is a GGML file format obtained from [TheBloke/Llama-2-7B-Chat-GGML](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML)."
      ],
      "metadata": {
        "id": "EnJbVaa06ZOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Install Prerequisite libraries**\n",
        "\n",
        "- Important: llama-cpp-python, 0.1.78 import\n",
        "- [llama-cpp-python library](https://github.com/abetlen/llama-cpp-python?tab=readme-ov-file) can be installed directly from PyPI as a source distribution by running"
      ],
      "metadata": {
        "id": "eKPYllI56GqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python==0.1.78"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "ND066NJK_BSN",
        "outputId": "79973cb9-b60f-40ca-a6c6-6e2e4a5365bb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python==0.1.78\n",
            "  Downloading llama_cpp_python-0.1.78.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.1.78) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.1.78) (1.23.5)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.1.78) (5.6.3)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.78-cp310-cp310-linux_x86_64.whl size=296587 sha256=cc799658cb4280a073ef26da589fd5a9b5de1d30b6b42d5bf11fc4b5b695d680\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/f9/20/9ca660a9d3f2a47e44217059409478865948b5c8a1cba70030\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: llama-cpp-python\n",
            "  Attempting uninstall: llama-cpp-python\n",
            "    Found existing installation: llama_cpp_python 0.2.20\n",
            "    Uninstalling llama_cpp_python-0.2.20:\n",
            "      Successfully uninstalled llama_cpp_python-0.2.20\n",
            "Successfully installed llama-cpp-python-0.1.78\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "llama_cpp"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Download Llama 2**"
      ],
      "metadata": {
        "id": "2nsdtTna7j9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q2_K.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROkquB4N722I",
        "outputId": "5ed0142e-effc-48c2-8a98-cfd124ba7243"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-09 09:46:34--  https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q2_K.bin\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.23, 18.164.174.55, 18.164.174.17, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/30/e3/30e3aca7233f7337633262ff6d59dd98559ecd8982e7419b39752c8d0daae1ca/45833e0b59c8fe80676c664f556031fc411da8856e0716ac7b8ed201b7221c08?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27llama-2-7b-chat.ggmlv3.q2_K.bin%3B+filename%3D%22llama-2-7b-chat.ggmlv3.q2_K.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1702374394&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjM3NDM5NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy8zMC9lMy8zMGUzYWNhNzIzM2Y3MzM3NjMzMjYyZmY2ZDU5ZGQ5ODU1OWVjZDg5ODJlNzQxOWIzOTc1MmM4ZDBkYWFlMWNhLzQ1ODMzZTBiNTljOGZlODA2NzZjNjY0ZjU1NjAzMWZjNDExZGE4ODU2ZTA3MTZhYzdiOGVkMjAxYjcyMjFjMDg%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=cBTNWbilviYfvOLUoSmauFIhiJmZE9tckxw0KZ1%7EX8AKRnozbb8p61VE2ucvRjTOJNcHnruMjIARTqUToqJB0iQuVoyv0dHZBuST0vO36OUymBVP-OCbhKLzLMp9WJRtqyOJuAYxenB%7EmgKqfMg4PQkQnuCxE%7EdTLTBxOzk51YSpo1-wDVsE-z7if9Q9-6lcU0M-8uWSLFHzvFvO-XBSzKyUpyEHy8PVbl-n6kmsQIpDvEMpKkdvgz1Q7yTAadzKlG6C39uBKpF1grbkTVaYCX93woNdlDiHY-gBACwknr3TVEeHDzbYHdrR7gwm1c7ut99TUqgaBVc%7EVko4GMX3aw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-12-09 09:46:34--  https://cdn-lfs.huggingface.co/repos/30/e3/30e3aca7233f7337633262ff6d59dd98559ecd8982e7419b39752c8d0daae1ca/45833e0b59c8fe80676c664f556031fc411da8856e0716ac7b8ed201b7221c08?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27llama-2-7b-chat.ggmlv3.q2_K.bin%3B+filename%3D%22llama-2-7b-chat.ggmlv3.q2_K.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1702374394&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjM3NDM5NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy8zMC9lMy8zMGUzYWNhNzIzM2Y3MzM3NjMzMjYyZmY2ZDU5ZGQ5ODU1OWVjZDg5ODJlNzQxOWIzOTc1MmM4ZDBkYWFlMWNhLzQ1ODMzZTBiNTljOGZlODA2NzZjNjY0ZjU1NjAzMWZjNDExZGE4ODU2ZTA3MTZhYzdiOGVkMjAxYjcyMjFjMDg%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=cBTNWbilviYfvOLUoSmauFIhiJmZE9tckxw0KZ1%7EX8AKRnozbb8p61VE2ucvRjTOJNcHnruMjIARTqUToqJB0iQuVoyv0dHZBuST0vO36OUymBVP-OCbhKLzLMp9WJRtqyOJuAYxenB%7EmgKqfMg4PQkQnuCxE%7EdTLTBxOzk51YSpo1-wDVsE-z7if9Q9-6lcU0M-8uWSLFHzvFvO-XBSzKyUpyEHy8PVbl-n6kmsQIpDvEMpKkdvgz1Q7yTAadzKlG6C39uBKpF1grbkTVaYCX93woNdlDiHY-gBACwknr3TVEeHDzbYHdrR7gwm1c7ut99TUqgaBVc%7EVko4GMX3aw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.132.97, 18.154.132.23, 18.154.132.81, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.132.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2866807424 (2.7G) [application/octet-stream]\n",
            "Saving to: ‘llama-2-7b-chat.ggmlv3.q2_K.bin’\n",
            "\n",
            "llama-2-7b-chat.ggm 100%[===================>]   2.67G   154MB/s    in 28s     \n",
            "\n",
            "2023-12-09 09:47:02 (96.3 MB/s) - ‘llama-2-7b-chat.ggmlv3.q2_K.bin’ saved [2866807424/2866807424]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Load Llama 2 Model**"
      ],
      "metadata": {
        "id": "XpHdIAhA8Avy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "llm = Llama(model_path=\"/content/llama-2-7b-chat.ggmlv3.q2_K.bin\", n_ctx=512, n_batch=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zjdl-vxJ8FSE",
        "outputId": "4ce2ac2b-1dd2-4e5f-f46c-3d1bcd8c021f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Generate LLM response**"
      ],
      "metadata": {
        "id": "4Q_-IHVR_vaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "\n",
        "time.sleep(10)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mXt-acV_tHi",
        "outputId": "5c9b951e-ae61-49d2-be68-4cc4eb67dd44"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time:  10.010437739000281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "\n",
        "#Perform LLM response generation\n",
        "prompt = \"Please organize the following sentences into a summary sentence and three key points. \"\n",
        "prompt = prompt + \"Carnival is the largest cruise operator in the world, with over 90 ships that host almost 13 million guests annually. Cruises are in high demand, as consumers take advantage of the value gap between cruise and land-based vacations. However, the stock is down 72% from where it traded five years ago. There are a few reasons this could be the buying opportunity of a lifetime for this leading cruise brand.\"\n",
        "prompt = prompt + \"The business looked like a mess during the pandemic, but the company's growth opportunity is attractive. The gap between cruise pricing and land-based vacations is a near-term catalyst for growth. Carnival's revenue is on pace to grow 76% this year, based on consensus estimates and is expected to grow another 13% next year.\"\n",
        "prompt = prompt + \"Strong demand is pushing profits up. Earnings per share (EPS) were deep in the red a few years ago but are improving significantly along with revenue. Analysts expect adjusted EPS to reach $0.91 in 2024.\"\n",
        "\n",
        "output = llm(prompt,\n",
        "             max_tokens=-1,\n",
        "             echo=False,\n",
        "             temperature=0.1,\n",
        "             top_p=0.9)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VefhsMbSAIAl",
        "outputId": "3f5617e4-3fa7-469b-fee4-e676f4b7075a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time:  190.37276879399997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Display Generated Text**"
      ],
      "metadata": {
        "id": "pGp8FrpQAk0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crG_KVYDAqOw",
        "outputId": "04d0958d-d0ed-4776-911a-bae64fe83071"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'cmpl-65a6e364-bd91-44dd-ae7d-a62632dc7fe5',\n",
              " 'object': 'text_completion',\n",
              " 'created': 1702116284,\n",
              " 'model': '/content/llama-2-7b-chat.ggmlv3.q2_K.bin',\n",
              " 'choices': [{'text': '\\n\\nSummary sentence: Carnival Corporation is the largest cruise operator',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'length'}],\n",
              " 'usage': {'prompt_tokens': 113, 'completion_tokens': 15, 'total_tokens': 128}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRZs8mlGBJrW",
        "outputId": "ef3bf91a-7bae-4a25-f827-7a7257774c7e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The company has also been paying out dividends for over 50 years, and its yield is currently 3.6%.\n",
            "\n",
            "Summary: Carnival is the largest cruise operator in the world with over 90 ships hosting almost 13 million guests annually. Despite a decline in stock price over the past five years, there are reasons to believe this could be a buying opportunity of a lifetime for the leading cruise brand.\n",
            "\n",
            "Key Points:\n",
            "\n",
            "1. Cruises are in high demand as consumers take advantage of the value gap between cruise and land-based vacations.\n",
            "2. The stock price has declined 72% from where it traded five years ago, presenting a potential buying opportunity.\n",
            "3. Carnival's revenue is on pace to grow 76% this year and another 13% next year, driven by strong demand and improving profitability.\n"
          ]
        }
      ]
    }
  ]
}